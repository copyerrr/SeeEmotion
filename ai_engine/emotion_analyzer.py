"""
ê°ì •ë¶„ì„ ëª¨ë¸ ë¡œë“œ ë° ì¶”ë¡  í´ë˜ìŠ¤
"""
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from typing import Dict, Optional
import os


class EmotionAnalyzer:
    """Electra ê¸°ë°˜ ê°ì •ë¶„ì„ ëª¨ë¸"""
    
    # ê°ì •ë³„ ìƒ‰ìƒ ë§¤í•‘ (ANSI ìƒ‰ìƒ ì½”ë“œ)
    EMOTION_COLORS = {
        "Anxiety": "\033[93m",      # ë…¸ë€ìƒ‰
        "Joy": "\033[92m",           # ì´ˆë¡ìƒ‰
        "Sadness": "\033[94m",       # íŒŒë€ìƒ‰
        "Fear": "\033[95m",          # ìí™ìƒ‰
        "Anger": "\033[91m",         # ë¹¨ê°„ìƒ‰
        "Neutral": "\033[97m",       # í°ìƒ‰
    }
    
    # ê°ì •ë³„ í•œê¸€ ì´ë¦„
    EMOTION_NAMES_KO = {
        "Anxiety": "ë¶ˆì•ˆ",
        "Joy": "ê¸°ì¨",
        "Sadness": "ìŠ¬í””",
        "Fear": "ê³µí¬",
        "Anger": "ë¶„ë…¸",
        "Neutral": "ì¤‘ë¦½",
    }
    
    RESET_COLOR = "\033[0m"  # ìƒ‰ìƒ ë¦¬ì…‹
    
    def __init__(self, model_path: str, device: Optional[str] = None):
        """
        Args:
            model_path: ëª¨ë¸ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
            device: 'cuda' ë˜ëŠ” 'cpu' (Noneì´ë©´ ìë™ ì„ íƒ)
        """
        self.model_path = model_path
        self.device = device if device else ("cuda" if torch.cuda.is_available() else "cpu")
        
        print(f"ğŸ“¦ ê°ì •ë¶„ì„ ëª¨ë¸ ë¡œë”© ì¤‘... ({self.device})")
        
        # í† í¬ë‚˜ì´ì € ë¡œë“œ
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
        self.model.to(self.device)
        self.model.eval()
        
        # ë ˆì´ë¸” ë§¤í•‘ (config.jsonì—ì„œ ê°€ì ¸ì˜´)
        self.id2label = {
            0: "Anxiety",
            1: "Joy",
            2: "Sadness",
            3: "Fear",
            4: "Anger",
            5: "Neutral"
        }
        
        print("âœ… ê°ì •ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    def predict(self, text: str) -> Dict:
        """
        í…ìŠ¤íŠ¸ì— ëŒ€í•œ ê°ì • ì˜ˆì¸¡
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            
        Returns:
            {
                'emotion': ê°ì • ì´ë¦„,
                'emotion_ko': ê°ì • í•œê¸€ ì´ë¦„,
                'color': ANSI ìƒ‰ìƒ ì½”ë“œ,
                'confidence': í™•ë¥ 
            }
        """
        if not text or not text.strip():
            return {
                'emotion': 'Neutral',
                'emotion_ko': 'ì¤‘ë¦½',
                'color': self.EMOTION_COLORS['Neutral'],
                'confidence': 1.0
            }
        
        # í† í¬ë‚˜ì´ì§•
        encoded = self.tokenizer(
            text,
            max_length=512,
            padding=True,
            truncation=True,
            return_tensors='pt'
        )
        
        input_ids = encoded['input_ids'].to(self.device)
        attention_mask = encoded['attention_mask'].to(self.device)
        
        # ì˜ˆì¸¡
        with torch.no_grad():
            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)
            logits = outputs.logits
            probs = torch.softmax(logits, dim=-1)
            prediction = torch.argmax(logits, dim=-1).item()
            confidence = probs[0][prediction].item()
        
        emotion = self.id2label.get(prediction, "Neutral")
        
        return {
            'emotion': emotion,
            'emotion_ko': self.EMOTION_NAMES_KO.get(emotion, "ì¤‘ë¦½"),
            'color': self.EMOTION_COLORS.get(emotion, self.EMOTION_COLORS['Neutral']),
            'confidence': confidence
        }
    
    def format_text_with_emotion(self, text: str, emotion_result: Dict) -> str:
        """
        ê°ì •ì— ë”°ë¥¸ ìƒ‰ìƒì´ ì ìš©ëœ í…ìŠ¤íŠ¸ ë°˜í™˜
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            emotion_result: predict() ë©”ì„œë“œì˜ ë°˜í™˜ê°’
            
        Returns:
            ìƒ‰ìƒì´ ì ìš©ëœ í…ìŠ¤íŠ¸
        """
        color = emotion_result['color']
        return f"{color}{text}{self.RESET_COLOR}"

